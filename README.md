# Proyecto DataOps â€“ ETL Automatizado

Este proyecto implementa un pipeline ETL automatizado como parte de un ejercicio acadÃ©mico en el diplomado de IngenierÃ­a de Datos. El flujo extrae datos desde una base de datos PostgreSQL, aplica transformaciones con Python y exporta los resultados en formato CSV. Todo el proceso estÃ¡ empaquetado en Docker y preparado para ejecutarse mediante Jenkins en un flujo CI/CD.

## ğŸ“¦ Estructura del proyecto

```
dataops-rrhh/
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ main.py              # Script ETL principal
â”‚   â”œâ”€â”€ requirements.txt     # Dependencias de Python
â”œâ”€â”€ output/                  # Carpeta para archivos exportados (.csv)
â”œâ”€â”€ Dockerfile               # Imagen Docker para empaquetar y ejecutar el ETL
â”œâ”€â”€ jenkins/
â”‚   â””â”€â”€ Jenkinsfile          # DeclaraciÃ³n del pipeline CI/CD
â”œâ”€â”€ docs/                    # DocumentaciÃ³n tÃ©cnica y capturas
â””â”€â”€ README.md                # Este archivo
```

## ğŸš€ Instrucciones de uso

### â–¶ï¸ 1. Ejecutar localmente (recomendado para desarrollo)
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
pip install -r etl/requirements.txt
python etl/main.py
```

### ğŸ³ 2. Ejecutar con Docker
```bash
docker build -t etl-job .
docker run --rm -v "$(pwd)/output:/app/output" etl-job
```

> âš ï¸ Si usas Git Bash en Windows y hay espacios en tu ruta, usa:
> `winpty docker run --rm -v "$(pwd)/output:/app/output" etl-job`

### ğŸ” 3. Ejecutar en Jenkins
El Jenkinsfile contiene las instrucciones para clonar el repositorio, construir la imagen y ejecutar el ETL automÃ¡ticamente.

## âš™ï¸ Requisitos

- Python 3.10+ (usado localmente: 3.13.2)
- Docker
- Jenkins (para CI/CD)
- Acceso a PostgreSQL (credenciales provistas por el diplomado)

## ğŸ“„ Licencia

Este proyecto es de uso acadÃ©mico y no debe utilizarse en producciÃ³n sin validaciÃ³n adicional.
