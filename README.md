# Proyecto ETL con Docker y Jenkins (DataOps)

Este proyecto implementa un flujo ETL utilizando Python, PostgreSQL, Docker y Jenkins como parte de una prÃ¡ctica del diplomado de IngenierÃ­a de Datos. El proceso sigue los principios de DataOps, incorporando automatizaciÃ³n, trazabilidad y despliegue controlado.

---

## Estructura del Proyecto


dataops-rrhh/
â”‚
â”œâ”€â”€ etl/                    # Contiene el script ETL (main.py) y el requirements.txt
â”œâ”€â”€ output/                 # Archivos CSV generados por el ETL
â”œâ”€â”€ docs/                   # DocumentaciÃ³n del proyecto
â”œâ”€â”€ .gitignore              # Archivos a excluir del control de versiones
â”œâ”€â”€ Dockerfile              # Imagen Docker para ejecutar el ETL
â”œâ”€â”€ instalacionDocker.sh    # Script para preparar entorno en la VM
â”œâ”€â”€ docker-compose.yml      # Define el contenedor Jenkins
â””â”€â”€ README.md               # Este archivo


---

## TecnologÃ­as utilizadas

- *Python 3.13.2*  
- *Pandas, SQLAlchemy, Psycopg2*  
- *Docker Desktop (local)*  
- *PostgreSQL (remoto)*  
- *Jenkins (en VM Ubuntu con Docker)*  
- *Git + GitHub*

---

## Instrucciones de ejecuciÃ³n local (opcional)

1. Clonar el repositorio:

bash
git clone https://github.com/tu-usuario/dataops-rrhh.git
cd dataops-rrhh


2. Crear entorno virtual:

bash
python -m venv venv
source venv/Scripts/activate  # En Windows


3. Instalar dependencias:

bash
pip install -r etl/requirements.txt


4. Ejecutar el ETL localmente:

bash
python etl/main.py


---

## Ejecutar con Docker

bash
docker build -t etl-job .
docker run --rm -v "$PWD/output:/app/output" etl-job


*Si usas Git Bash y tienes rutas con espacios, usa winpty*:

bash
winpty docker run --rm -v "$PWD/output:/app/output" etl-job


---

## AutomatizaciÃ³n CI/CD con Jenkins

- Jenkins fue desplegado en una VM Ubuntu mediante Docker
- Se configurÃ³ un *proyecto libre*, sin Jenkinsfile
- El pipeline realiza:
  1. ClonaciÃ³n del repositorio
  2. ConstrucciÃ³n de la imagen etl-job
  3. EjecuciÃ³n del contenedor que genera el archivo .csv
- Se habilitÃ³ un *webhook de GitHub* para disparar el pipeline automÃ¡ticamente ante cada push

---

## DocumentaciÃ³n

La documentaciÃ³n completa se encuentra en la carpeta docs/ e incluye:

- DescripciÃ³n del flujo ETL
- Estructura del proyecto
- Evidencia del pipeline funcionando
- ConfiguraciÃ³n del entorno

---

## ðŸ™Œ Autor

*Joaquin Ruiz Ramal*  